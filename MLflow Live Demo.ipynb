{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6505a7ad",
   "metadata": {},
   "source": [
    "## What is MLFlow and its Components\n",
    "\n",
    "MLFLow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry. MLFLow currently offers four components:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745f450",
   "metadata": {},
   "source": [
    "<img src=\"mlflow.png\">\n",
    "\n",
    "\n",
    "https://www.mlflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44a8b9",
   "metadata": {},
   "source": [
    "_First thing first_\n",
    "### Create Conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb0ce0",
   "metadata": {},
   "source": [
    "##### run below commands in terminal but make sure conda is installed or use anaconda prompt which you will get as part of anaconda installation\n",
    "\n",
    "1. `conda create -n envname python=3.9 ipykernel` \n",
    "it will create a conda env named envname and install python version 3.9 and a ipykernel inside this environment\n",
    "\n",
    "2. Activate the environment\n",
    "`conda activate envname`\n",
    "\n",
    "3. add newly created environment to the notebook as kernel\n",
    "`python -m ipykernel install --user --name=envname` \n",
    "\n",
    "4. install notebook inside the environment\n",
    "`pip install notebook`\n",
    "\n",
    "5. Now install all required dependencies to run this notebook\n",
    "\n",
    "* `pip install pandas`\n",
    "* `pip install numpy`\n",
    "* `pip install scikit-learn`\n",
    "* `pip install imblearn`\n",
    "* `pip install matplotlib`\n",
    "* `pip install mlflow`\n",
    "\n",
    "Now open the notebook using below command: (from the anaconda prompt inside conda environment)\n",
    "\n",
    "`jupyter notebook`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5a6b9",
   "metadata": {},
   "source": [
    "#### Make sure python is used from your newly created environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd81db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/coding/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3caf80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ff2b8",
   "metadata": {},
   "source": [
    "### Create functions for all the steps involved in complete model training lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1ea93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f0efd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9e53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5611082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.021</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>success</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.729</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.869</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education  default housing loan  \\\n",
       "0   44  blue-collar  married           basic.4y  unknown     yes   no   \n",
       "1   53   technician  married            unknown       no      no   no   \n",
       "2   28   management   single  university.degree       no     yes   no   \n",
       "3   39     services  married        high.school       no      no   no   \n",
       "4   55      retired  married           basic.4y       no     yes   no   \n",
       "\n",
       "    contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0  cellular   aug         thu  ...         1    999         0  nonexistent   \n",
       "1  cellular   nov         fri  ...         1    999         0  nonexistent   \n",
       "2  cellular   jun         thu  ...         3      6         2      success   \n",
       "3  cellular   apr         fri  ...         2    999         0  nonexistent   \n",
       "4  cellular   aug         fri  ...         1      3         1      success   \n",
       "\n",
       "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
       "0          1.4          93.444          -36.1      4.963       5228.1  0  \n",
       "1         -0.1          93.200          -42.0      4.021       5195.8  0  \n",
       "2         -1.7          94.055          -39.8      0.729       4991.6  1  \n",
       "3         -1.8          93.075          -47.1      1.405       5099.1  0  \n",
       "4         -2.9          92.201          -31.4      0.869       5076.2  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data('https://raw.githubusercontent.com/TripathiAshutosh/dataset/main/banking.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdca67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    print(\"na values available in data \\n\")\n",
    "    print(data.isna().sum())\n",
    "    data = data.dropna()\n",
    "    print(\"after droping na values \\n\")\n",
    "    print(data.isna().sum())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d378c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    data['education']=np.where(data['education'] =='basic.9y', 'Basic', data['education'])\n",
    "    data['education']=np.where(data['education'] =='basic.6y', 'Basic', data['education'])\n",
    "    data['education']=np.where(data['education'] =='basic.4y', 'Basic', data['education'])\n",
    "    \n",
    "    cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "    for var in cat_vars:\n",
    "        cat_list='var'+'_'+var\n",
    "        cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "        data1=data.join(cat_list)\n",
    "        data=data1\n",
    "\n",
    "    cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "    data_vars=data.columns.values.tolist()\n",
    "    to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "    \n",
    "    final_data=data[to_keep]\n",
    "    \n",
    "    \n",
    "    final_data.columns = final_data.columns.str.replace('.','_')\n",
    "    final_data.columns = final_data.columns.str.replace(' ','_')\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f78530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(final_data):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X = final_data.loc[:, final_data.columns != 'y']\n",
    "    y = final_data.loc[:, final_data.columns == 'y']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify = y, random_state=47)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eb6095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling_target_class(X_train, y_train):\n",
    "    ### Over-sampling using SMOTE \n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    os = SMOTE(random_state=0)\n",
    "\n",
    "    columns = X_train.columns\n",
    "    os_data_X,os_data_y=os.fit_resample(X_train, y_train)\n",
    "\n",
    "    os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "    os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "    # we can Check the numbers of our data\n",
    "    print(\"length of oversampled data is \",len(os_data_X))\n",
    "    print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "    print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "    print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "    print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))\n",
    "    \n",
    "    X_train = os_data_X\n",
    "    y_train = os_data_y['y']\n",
    " \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c85667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_basic_classifier(X_train,y_train):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=101)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce3c96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_data(model,X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a475cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_prob_on_test_data(model,X_test):\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ccc67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, y_pred_prob):\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,log_loss\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    entropy = log_loss(y_true, y_pred_prob)\n",
    "    return {'accuracy': round(acc, 2), 'precision': round(prec, 2), 'recall': round(recall, 2), 'entropy': round(entropy, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca1aeebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roc_auc_plot(clf, X_data, y_data):\n",
    "    # Get predicted probabilities for the positive class\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve,auc\n",
    "    y_score = clf.predict_proba(X_data)[:, 1]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_data, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_auc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db16c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix_plot(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        clf, X_test, y_test, cmap=plt.cm.Blues)\n",
    "    disp.plot()\n",
    "    plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3aec48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter_tuning(X_train, y_train):\n",
    "    # define random parameters grid\n",
    "    n_estimators = [5,21,51,101] # number of trees in the random forest\n",
    "    max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
    "    max_depth = [int(x) for x in np.linspace(10, 120, num = 12)] # maximum number of levels allowed in each decision tree\n",
    "    min_samples_split = [2, 6, 10] # minimum sample number to split a node\n",
    "    min_samples_leaf = [1, 3, 4] # minimum sample number that can be stored in a leaf node\n",
    "    bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': min_samples_split,\n",
    "                    'min_samples_leaf': min_samples_leaf,\n",
    "                    'bootstrap': bootstrap\n",
    "                  }\n",
    "    \n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier()\n",
    "    model_tuning = RandomizedSearchCV(estimator = classifier, param_distributions = random_grid,\n",
    "                   n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
    "    model_tuning.fit(X_train, y_train)\n",
    "\n",
    "    print ('Random grid: ', random_grid, '\\n')\n",
    "    # print the best parameters\n",
    "    print ('Best Parameters: ', model_tuning.best_params_, ' \\n')\n",
    "\n",
    "    best_params = model_tuning.best_params_\n",
    "    \n",
    "    n_estimators = best_params['n_estimators']\n",
    "    min_samples_split = best_params['min_samples_split']\n",
    "    min_samples_leaf = best_params['min_samples_leaf']\n",
    "    max_features = best_params['max_features']\n",
    "    max_depth = best_params['max_depth']\n",
    "    bootstrap = best_params['bootstrap']\n",
    "    \n",
    "    model_tuned = RandomForestClassifier(n_estimators = n_estimators, min_samples_split = min_samples_split,\n",
    "                                         min_samples_leaf= min_samples_leaf, max_features = max_features,\n",
    "                                         max_depth= max_depth, bootstrap=bootstrap) \n",
    "    model_tuned.fit( X_train, y_train)\n",
    "    return model_tuned,best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aeb7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8acce9f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = load_data('https://raw.githubusercontent.com/TripathiAshutosh/dataset/main/banking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "376d0587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na values available in data \n",
      "\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp_var_rate      0\n",
      "cons_price_idx    0\n",
      "cons_conf_idx     0\n",
      "euribor3m         0\n",
      "nr_employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "after droping na values \n",
      "\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp_var_rate      0\n",
      "cons_price_idx    0\n",
      "cons_conf_idx     0\n",
      "euribor3m         0\n",
      "nr_employed       0\n",
      "y                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = data_cleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8e4a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = preprocessing(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bbb6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8da133cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  51166\n",
      "Number of no subscription in oversampled data 25583\n",
      "Number of subscription 25583\n",
      "Proportion of no subscription data in oversampled data is  0.5\n",
      "Proportion of subscription data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = over_sampling_target_class(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c0e3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = training_basic_classifier(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b485e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_on_test_data(model,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55d29fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19e4fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = predict_prob_on_test_data(model,X_test) #model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f7765b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97029703, 0.02970297],\n",
       "       ...,\n",
       "       [0.99009901, 0.00990099],\n",
       "       [0.72277228, 0.27722772],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceef3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bdeda22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.91, 'precision': 0.62, 'recall': 0.54, 'entropy': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(run_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ff3c7fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "too many positional arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m create_roc_auc_plot(model, X_test, y_test)\n",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m, in \u001b[0;36mcreate_roc_auc_plot\u001b[0;34m(clf, X_data, y_data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m roc_curve\n\u001b[0;32m----> 4\u001b[0m roc_curve(clf, X_data, y_data) \n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39msavefig(\u001b[39m'\u001b[39m\u001b[39mroc_auc_curve.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/coding/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m params \u001b[39m=\u001b[39m func_sig\u001b[39m.\u001b[39;49mbind(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    190\u001b[0m params\u001b[39m.\u001b[39mapply_defaults()\n\u001b[1;32m    192\u001b[0m \u001b[39m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:3212\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   3208\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m \u001b[39m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m \u001b[39m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3212\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bind(args, kwargs)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:3138\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3134\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3135\u001b[0m     \u001b[39mif\u001b[39;00m param\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m (_VAR_KEYWORD, _KEYWORD_ONLY):\n\u001b[1;32m   3136\u001b[0m         \u001b[39m# Looks like we have no parameter for this positional\u001b[39;00m\n\u001b[1;32m   3137\u001b[0m         \u001b[39m# argument\u001b[39;00m\n\u001b[0;32m-> 3138\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   3139\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mtoo many positional arguments\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3141\u001b[0m     \u001b[39mif\u001b[39;00m param\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m _VAR_POSITIONAL:\n\u001b[1;32m   3142\u001b[0m         \u001b[39m# We have an '*args'-like argument, let's fill it with\u001b[39;00m\n\u001b[1;32m   3143\u001b[0m         \u001b[39m# all positional arguments we have left and move on to\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m         \u001b[39m# the next phase\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m         values \u001b[39m=\u001b[39m [arg_val]\n",
      "\u001b[0;31mTypeError\u001b[0m: too many positional arguments"
     ]
    }
   ],
   "source": [
    "create_roc_auc_plot(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ce51f26",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ConfusionMatrixDisplay.__init__() missing 1 required positional argument: 'confusion_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m create_confusion_matrix_plot(model, X_test, y_test)\n",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m, in \u001b[0;36mcreate_confusion_matrix_plot\u001b[0;34m(clf, X_test, y_test)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix,ConfusionMatrixDisplay\n\u001b[0;32m----> 4\u001b[0m ConfusionMatrixDisplay()(clf, X_test, y_test)\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39msavefig(\u001b[39m'\u001b[39m\u001b[39mconfusion_matrix.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: ConfusionMatrixDisplay.__init__() missing 1 required positional argument: 'confusion_matrix'"
     ]
    }
   ],
   "source": [
    "create_confusion_matrix_plot(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc429fce",
   "metadata": {},
   "source": [
    "### MLFlow work Starts from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5756180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.91, 'precision': 0.62, 'recall': 0.51, 'entropy': 0.2}\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"basic_classifier\" ##basic classifier\n",
    "run_name=\"term_deposit\"\n",
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)\n",
    "print(run_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af260494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - term_deposit is logged to Experiment - basic_classifier\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name,run_name,run_metrics,model,'confusion_matrix.png', 'roc_auc_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a00fb",
   "metadata": {},
   "source": [
    "### Function to create an experiment in MLFlow and log parameters, metrics and artifacts files like images etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26f2c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name,run_name, run_metrics,model, confusion_matrix_path = None, \n",
    "                      roc_auc_plot_path = None, run_params=None):\n",
    "    import mlflow\n",
    "    #mlflow.set_tracking_uri(\"http://localhost:5000\") #uncomment this line if you want to use any database like sqlite as backend storage for model\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        if not run_params == None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param, run_params[param])\n",
    "            \n",
    "        for metric in run_metrics:\n",
    "            mlflow.log_metric(metric, run_metrics[metric])\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        if not confusion_matrix_path == None:\n",
    "            mlflow.log_artifact(confusion_matrix_path, 'confusion_materix')\n",
    "            \n",
    "        if not roc_auc_plot_path == None:\n",
    "            mlflow.log_artifact(roc_auc_plot_path, \"roc_auc_plot\")\n",
    "        \n",
    "        mlflow.set_tag(\"tag1\", \"Random Forest\")\n",
    "        mlflow.set_tags({\"tag2\":\"Randomized Search CV\", \"tag3\":\"Production\"})\n",
    "            \n",
    "    print('Run - %s is logged to Experiment - %s' %(run_name, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5b47c",
   "metadata": {},
   "source": [
    "### Create another experiment after tuning hyperparameters and log the best set of parameters for which model gives the optimal performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a0d0f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashutosh Tripathi\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random grid:  {'n_estimators': [5, 21, 51, 101], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120], 'min_samples_split': [2, 6, 10], 'min_samples_leaf': [1, 3, 4], 'bootstrap': [True, False]} \n",
      "\n",
      "Best Parameters:  {'n_estimators': 101, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 50, 'bootstrap': True}  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashutosh Tripathi\\anaconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "experiment_name = \"optimized model\"\n",
    "run_name=\"Random_Search_CV_Tuned_Model\"\n",
    "model_tuned,best_params = hyper_parameter_tuning(X_train, y_train)\n",
    "run_params = best_params\n",
    "\n",
    "y_pred = predict_on_test_data(model_tuned,X_test) #will return the predicted class\n",
    "y_pred_prob = predict_prob_on_test_data(model_tuned,X_test) #model.predict_proba(X_test)\n",
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "163fd982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.91, 'precision': 0.61, 'recall': 0.57, 'entropy': 0.2}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d8bafa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators 101\n",
      "min_samples_split 10\n",
      "min_samples_leaf 4\n",
      "max_features auto\n",
      "max_depth 50\n",
      "bootstrap True\n"
     ]
    }
   ],
   "source": [
    "for param in run_params:\n",
    "    print(param, run_params[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f520e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - Random_Search_CV_Tuned_Model is logged to Experiment - optimized model\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name,run_name,run_metrics,model_tuned,'confusion_matrix.png', 'roc_auc_curve.png',run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a466fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7da88ce8",
   "metadata": {},
   "source": [
    "\n",
    "### if want to use the model registry feature, we need a database.\n",
    "\n",
    "#### _If you have MySQL installed then you can use the below command:_\n",
    "\n",
    "1. Create a database to use as an MLflow backend tracking server.\n",
    "\n",
    "`CREATE DATABASE mlflow_tracking_database;`\n",
    "\n",
    "2. Start MLflow tracking server using MySQL as a backend tracking store.\n",
    "` mlflow server \\\n",
    "   --backend-store-uri  mysql+pymysql://root@localhost/mlflow_tracking_database \\ \n",
    "   --default-artifact-root  file:/./mlruns \\\n",
    "   -h 0.0.0.0 -p 5000`\n",
    "\n",
    "\n",
    "3. Set the MLflow tracking uri (within code section).\n",
    "\n",
    "  mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "#### _If you have sqlite installed then you can use the below command:_\n",
    "\n",
    "1. Start MLflow tracking server using sqlite as a backend tracking store.\n",
    "\n",
    "`mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 --port 5000`\n",
    "\n",
    "\n",
    "2. Set the MLflow tracking uri (within code section).\n",
    "    \n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "\n",
    "You can also follow the official documentation for more information on backend database for model registry\n",
    "\n",
    "https://www.mlflow.org/docs/latest/model-registry.html#model-registry-workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51dadd7",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "Using MLFlow\n",
    "* How deploy models from model registry\n",
    "* Model serving both batch serving and online serving\n",
    "* MLFlow pipelines\n",
    "* Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7af37",
   "metadata": {},
   "source": [
    "# Thank You "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6b8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
